{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InceptionV3.ipynb","provenance":[],"authorship_tag":"ABX9TyNG1mmCUBKsqDstxhGqLrDm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4JxZK3JPiA2F","executionInfo":{"status":"ok","timestamp":1613038450939,"user_tz":-330,"elapsed":1622,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}}},"source":["import urllib.request\r\n","import os\r\n","import zipfile\r\n","import random\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from tensorflow.keras import layers\r\n","from tensorflow.keras import Model\r\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n","from tensorflow.keras.optimizers import RMSprop\r\n","from shutil import copyfile"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"mHrZ2o9QiORl","executionInfo":{"status":"ok","timestamp":1613038498277,"user_tz":-330,"elapsed":17536,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}}},"source":["data_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\r\n","data_file_name = \"catsdogs.zip\"\r\n","download_dir = 'tmp/'\r\n","urllib.request.urlretrieve(data_url, data_file_name)\r\n","zip_ref = zipfile.ZipFile(data_file_name, 'r')\r\n","zip_ref.extractall(download_dir)\r\n","zip_ref.close()"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jd-e3Wz6iieA","executionInfo":{"status":"ok","timestamp":1613038504983,"user_tz":-330,"elapsed":939,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}},"outputId":"6fe5da9c-eec6-4152-8c07-2335d92efb4c"},"source":["print(len(os.listdir('tmp/PetImages/Cat/')))\r\n","print(len(os.listdir('tmp/PetImages/Dog/')))\r\n","\r\n","\r\n","try:\r\n","    os.mkdir('tmp/cats-v-dogs')\r\n","    os.mkdir('tmp/cats-v-dogs/training')\r\n","    os.mkdir('tmp/cats-v-dogs/testing')\r\n","    os.mkdir('tmp/cats-v-dogs/training/cats')\r\n","    os.mkdir('tmp/cats-v-dogs/training/dogs')\r\n","    os.mkdir('tmp/cats-v-dogs/testing/cats')\r\n","    os.mkdir('tmp/cats-v-dogs/testing/dogs')\r\n","except OSError:\r\n","    pass"],"execution_count":18,"outputs":[{"output_type":"stream","text":["12501\n","12501\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MIn1xsHuinxs","executionInfo":{"status":"ok","timestamp":1613038532613,"user_tz":-330,"elapsed":983,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}}},"source":["import random\r\n","from shutil import copyfile\r\n","\r\n","\r\n","def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\r\n","    files = []\r\n","    for filename in os.listdir(SOURCE):\r\n","        file = SOURCE + filename\r\n","        if os.path.getsize(file) > 0:\r\n","            files.append(filename)\r\n","        else:\r\n","            print(filename + \" is zero length, so ignoring.\")\r\n","\r\n","    training_length = int(len(files) * SPLIT_SIZE)\r\n","    testing_length = int(len(files) - training_length)\r\n","    shuffled_set = random.sample(files, len(files))\r\n","    training_set = shuffled_set[0:training_length]\r\n","    testing_set = shuffled_set[:testing_length]\r\n","\r\n","    for filename in training_set:\r\n","        this_file = SOURCE + filename\r\n","        destination = TRAINING + filename\r\n","        copyfile(this_file, destination)\r\n","\r\n","    for filename in testing_set:\r\n","        this_file = SOURCE + filename\r\n","        destination = TESTING + filename\r\n","        copyfile(this_file, destination)\r\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sW_XEQgOi2_G","executionInfo":{"status":"ok","timestamp":1613038606954,"user_tz":-330,"elapsed":4687,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}},"outputId":"7dfb0149-5a91-44bb-e758-e8d6b2718fee"},"source":["\r\n","CAT_SOURCE_DIR = \"tmp/PetImages/Cat/\"\r\n","TRAINING_CATS_DIR = \"tmp/cats-v-dogs/training/cats/\"\r\n","TESTING_CATS_DIR = \"tmp/cats-v-dogs/testing/cats/\"\r\n","DOG_SOURCE_DIR = \"tmp/PetImages/Dog/\"\r\n","TRAINING_DOGS_DIR = \"tmp/cats-v-dogs/training/dogs/\"\r\n","TESTING_DOGS_DIR = \"tmp/cats-v-dogs/testing/dogs/\"\r\n","\r\n","split_size = .9\r\n","split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\r\n","split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\r\n","\r\n","# Expected output\r\n","# 666.jpg is zero length, so ignoring\r\n","# 11702.jpg is zero length, so ignoring\r\n","\r\n","print(len(os.listdir('tmp/cats-v-dogs/training/cats/')))\r\n","print(len(os.listdir('tmp/cats-v-dogs/training/dogs/')))\r\n","print(len(os.listdir('tmp/cats-v-dogs/testing/cats/')))\r\n","print(len(os.listdir('tmp/cats-v-dogs/testing/dogs/')))\r\n","\r\n","\r\n","TRAINING_DIR = \"tmp/cats-v-dogs/training/\"\r\n","# Experiment with your own parameters here to really try to drive it to 99.9% accuracy or better\r\n","train_datagen = ImageDataGenerator(rescale=1./255,\r\n","                                   rotation_range=40,\r\n","                                   width_shift_range=0.2,\r\n","                                   height_shift_range=0.2,\r\n","                                   shear_range=0.2,\r\n","                                   zoom_range=0.2,\r\n","                                   horizontal_flip=True,\r\n","                                   fill_mode='nearest')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["666.jpg is zero length, so ignoring.\n","11702.jpg is zero length, so ignoring.\n","11250\n","11250\n","1250\n","1250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5b1c8yyRjLaC","executionInfo":{"status":"ok","timestamp":1613038664927,"user_tz":-330,"elapsed":2040,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}},"outputId":"02c1ed00-9290-43b1-85c9-d2931b090d49"},"source":["train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\r\n","                                                    batch_size=100,\r\n","                                                    class_mode='binary',\r\n","                                                    target_size=(150, 150))\r\n","\r\n","VALIDATION_DIR = \"tmp/cats-v-dogs/testing/\"\r\n","# Experiment with your own parameters here to really try to drive it to 99.9% accuracy or better\r\n","validation_datagen = ImageDataGenerator(rescale=1./255)\r\n","validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\r\n","                                                              batch_size=100,\r\n","                                                              class_mode='binary',\r\n","                                                              target_size=(150, 150))\r\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Found 22498 images belonging to 2 classes.\n","Found 2500 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5O09sDmAjO4p","executionInfo":{"status":"ok","timestamp":1613038726027,"user_tz":-330,"elapsed":4509,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}}},"source":["weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\r\n","weights_file = \"inception_v3.h5\"\r\n","urllib.request.urlretrieve(weights_url, weights_file)\r\n","\r\n","pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\r\n","                                include_top=False,\r\n","                                weights=None)\r\n","\r\n","pre_trained_model.load_weights(weights_file)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TuNcj2ZjgcF","executionInfo":{"status":"ok","timestamp":1613061315057,"user_tz":-330,"elapsed":22540542,"user":{"displayName":"Prabal Kumar","photoUrl":"","userId":"07781316197818734249"}},"outputId":"ec025458-5bbd-429d-dda7-e49f85ec49ec"},"source":["for layer in pre_trained_model.layers:\r\n","    layer.trainable = False\r\n","\r\n","# pre_trained_model.summary()\r\n","\r\n","last_layer = pre_trained_model.get_layer('mixed7')\r\n","print('last layer output shape: ', last_layer.output_shape)\r\n","last_output = last_layer.output\r\n","\r\n","# Flatten the output layer to 1 dimension\r\n","x = layers.Flatten()(last_output)\r\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\r\n","x = layers.Dense(1024, activation='relu')(x)\r\n","# Add a dropout rate of 0.2\r\n","x = layers.Dropout(0.3)(x)\r\n","# Add a final sigmoid layer for classification\r\n","x = layers.Dense(1, activation='sigmoid')(x)\r\n","\r\n","model = Model(pre_trained_model.input, x)\r\n","\r\n","model.compile(optimizer=RMSprop(lr=0.0001),\r\n","              loss='binary_crossentropy',\r\n","              metrics=['acc'])\r\n","\r\n","history = model.fit_generator(\r\n","            train_generator,\r\n","            validation_data=validation_generator,\r\n","            epochs=20,\r\n","            verbose=1)\r\n","\r\n","model.save(\"catsdogs.h5\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["last layer output shape:  (None, 7, 7, 768)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n"," 44/225 [====>.........................] - ETA: 13:43 - loss: 0.7091 - acc: 0.7844"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["225/225 [==============================] - 1130s 5s/step - loss: 0.3657 - acc: 0.8716 - val_loss: 0.1119 - val_acc: 0.9584\n","Epoch 2/20\n","225/225 [==============================] - 1120s 5s/step - loss: 0.1560 - acc: 0.9374 - val_loss: 0.0762 - val_acc: 0.9720\n","Epoch 3/20\n","225/225 [==============================] - 1121s 5s/step - loss: 0.1432 - acc: 0.9408 - val_loss: 0.0974 - val_acc: 0.9644\n","Epoch 4/20\n","225/225 [==============================] - 1116s 5s/step - loss: 0.1424 - acc: 0.9440 - val_loss: 0.0738 - val_acc: 0.9760\n","Epoch 5/20\n","225/225 [==============================] - 1139s 5s/step - loss: 0.1356 - acc: 0.9465 - val_loss: 0.0674 - val_acc: 0.9772\n","Epoch 6/20\n","225/225 [==============================] - 1115s 5s/step - loss: 0.1272 - acc: 0.9498 - val_loss: 0.0614 - val_acc: 0.9796\n","Epoch 7/20\n","225/225 [==============================] - 1117s 5s/step - loss: 0.1324 - acc: 0.9476 - val_loss: 0.0603 - val_acc: 0.9804\n","Epoch 8/20\n","225/225 [==============================] - 1132s 5s/step - loss: 0.1286 - acc: 0.9502 - val_loss: 0.0614 - val_acc: 0.9792\n","Epoch 9/20\n","225/225 [==============================] - 1125s 5s/step - loss: 0.1249 - acc: 0.9525 - val_loss: 0.0625 - val_acc: 0.9804\n","Epoch 10/20\n","225/225 [==============================] - 1129s 5s/step - loss: 0.1246 - acc: 0.9530 - val_loss: 0.0624 - val_acc: 0.9792\n","Epoch 11/20\n","225/225 [==============================] - 1129s 5s/step - loss: 0.1246 - acc: 0.9538 - val_loss: 0.0602 - val_acc: 0.9820\n","Epoch 12/20\n","225/225 [==============================] - 1128s 5s/step - loss: 0.1133 - acc: 0.9583 - val_loss: 0.0715 - val_acc: 0.9760\n","Epoch 13/20\n","225/225 [==============================] - 1125s 5s/step - loss: 0.1251 - acc: 0.9552 - val_loss: 0.0624 - val_acc: 0.9816\n","Epoch 14/20\n","225/225 [==============================] - 1128s 5s/step - loss: 0.1099 - acc: 0.9599 - val_loss: 0.0640 - val_acc: 0.9792\n","Epoch 15/20\n","225/225 [==============================] - 1131s 5s/step - loss: 0.1118 - acc: 0.9589 - val_loss: 0.0637 - val_acc: 0.9792\n","Epoch 16/20\n","225/225 [==============================] - 1129s 5s/step - loss: 0.1172 - acc: 0.9557 - val_loss: 0.0646 - val_acc: 0.9824\n","Epoch 17/20\n","225/225 [==============================] - 1129s 5s/step - loss: 0.1080 - acc: 0.9594 - val_loss: 0.0603 - val_acc: 0.9796\n","Epoch 18/20\n","225/225 [==============================] - 1129s 5s/step - loss: 0.1082 - acc: 0.9589 - val_loss: 0.0615 - val_acc: 0.9820\n","Epoch 19/20\n","225/225 [==============================] - 1135s 5s/step - loss: 0.1027 - acc: 0.9630 - val_loss: 0.0547 - val_acc: 0.9828\n","Epoch 20/20\n","225/225 [==============================] - 1127s 5s/step - loss: 0.1093 - acc: 0.9618 - val_loss: 0.0659 - val_acc: 0.9792\n"],"name":"stdout"}]}]}